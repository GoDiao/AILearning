{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-06T08:25:46.303551Z","iopub.execute_input":"2024-05-06T08:25:46.303962Z","iopub.status.idle":"2024-05-06T08:25:47.178384Z","shell.execute_reply.started":"2024-05-06T08:25:46.303930Z","shell.execute_reply":"2024-05-06T08:25:47.177409Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#!pip install datasets transformers\n#transformers==4.9.2\n#datasets==1.11.0","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:25:47.180362Z","iopub.execute_input":"2024-05-06T08:25:47.181447Z","iopub.status.idle":"2024-05-06T08:25:47.185378Z","shell.execute_reply.started":"2024-05-06T08:25:47.181396Z","shell.execute_reply":"2024-05-06T08:25:47.184309Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"GLUE_TASKS = [\"cola\", \"mnli\", \"mnli-mm\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:25:47.186924Z","iopub.execute_input":"2024-05-06T08:25:47.187211Z","iopub.status.idle":"2024-05-06T08:25:47.195387Z","shell.execute_reply.started":"2024-05-06T08:25:47.187189Z","shell.execute_reply":"2024-05-06T08:25:47.194460Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom datasets import load_metric\ntask = 'sst2'\nactual_task = \"mnli\" if task == \"mnli-mm\" else task\ndataset = load_dataset(\"glue\", actual_task)\nmetric = load_metric('glue', actual_task)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:25:47.197627Z","iopub.execute_input":"2024-05-06T08:25:47.197911Z","iopub.status.idle":"2024-05-06T08:25:54.365466Z","shell.execute_reply.started":"2024-05-06T08:25:47.197884Z","shell.execute_reply":"2024-05-06T08:25:54.364630Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29b068636dbe42789eeb57ac2f2d2bc8"}},"metadata":{}},{"name":"stderr","text":"Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.11M/3.11M [00:00<00:00, 8.60MB/s]\nDownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.8k/72.8k [00:00<00:00, 334kB/s]\nDownloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 148k/148k [00:00<00:00, 708kB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9efe485e48b14cc7a76d959b8f052fac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb70ed7a13de450db83931bbdebdf12c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4dc6467758748449f94d0abe67d0620"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_34/2385546831.py:6: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  metric = load_metric('glue', actual_task)\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for glue contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/glue/glue.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a93528feb54a4ec9b155c33f0c056500"}},"metadata":{}}]},{"cell_type":"code","source":"import datasets\nimport random\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n    \n    df = pd.DataFrame(dataset[picks])\n    for column, typ in dataset.features.items():\n        if isinstance(typ, datasets.ClassLabel):\n            df[column] = df[column].transform(lambda i: typ.names[i])\n    display(HTML(df.to_html()))\n    \nshow_random_elements(dataset[\"train\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:25:54.366612Z","iopub.execute_input":"2024-05-06T08:25:54.367086Z","iopub.status.idle":"2024-05-06T08:25:54.394955Z","shell.execute_reply.started":"2024-05-06T08:25:54.367048Z","shell.execute_reply":"2024-05-06T08:25:54.394049Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>the ingenuity that parker displays in freshening the play is almost in a class with that of wilde himself .</td>\n      <td>positive</td>\n      <td>9739</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>of the most creative , energetic and original comedies to hit the screen in years</td>\n      <td>positive</td>\n      <td>34084</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>there are laughs aplenty , and , as a bonus , viewers do n't have to worry about being subjected to farts , urine , feces , semen , or any of the other foul substances that have overrun modern-day comedies .</td>\n      <td>positive</td>\n      <td>51750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>'s coherent , well shot , and</td>\n      <td>positive</td>\n      <td>63219</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>graphic treatment</td>\n      <td>positive</td>\n      <td>30691</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>cruel and</td>\n      <td>negative</td>\n      <td>51881</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>rare documentary</td>\n      <td>positive</td>\n      <td>26725</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>a complete wash</td>\n      <td>negative</td>\n      <td>65931</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>( less a movie than ) an appalling , odoriferous thing ... so rotten in almost every single facet of production that you 'll want to crawl up your own *** in embarrassment .</td>\n      <td>negative</td>\n      <td>13985</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>and , thanks to the presence of ` the king , ' it also rocks .</td>\n      <td>positive</td>\n      <td>1904</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"markdown","source":"* Obtain a tokenizer **corresponding to the pre-trained model** one by one.\n\n* When using the specified model checkpoint's corresponding tokenizer, the vocabulary required by the model, to be precise, is downloaded, which is the tokens vocabulary.","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\nmodel_checkpoint = \"distilbert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:25:54.395971Z","iopub.execute_input":"2024-05-06T08:25:54.396234Z","iopub.status.idle":"2024-05-06T08:26:00.142872Z","shell.execute_reply.started":"2024-05-06T08:25:54.396211Z","shell.execute_reply":"2024-05-06T08:26:00.141799Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cc9ed198eb94ba0bfce812590bb7a07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8d53da9c53a42e3bd9bbf4112515cd9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72e74ed206424ea6923e72b587fa1730"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f731b4c94aad489b9cde81dd81852d2d"}},"metadata":{}}]},{"cell_type":"markdown","source":"Example of Tokenize","metadata":{}},{"cell_type":"code","source":"batch_sentences = [\"Hello I'm a single sentence\",\n                   \"And another sentence\",\n                   \"And the very very last one\"]\nencoded_inputs = tokenizer(batch_sentences)\nprint(encoded_inputs)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:00.144218Z","iopub.execute_input":"2024-05-06T08:26:00.144916Z","iopub.status.idle":"2024-05-06T08:26:00.152292Z","shell.execute_reply.started":"2024-05-06T08:26:00.144880Z","shell.execute_reply":"2024-05-06T08:26:00.151381Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'input_ids': [[101, 7592, 1045, 1005, 1049, 1037, 2309, 6251, 102], [101, 1998, 2178, 6251, 102], [101, 1998, 1996, 2200, 2200, 2197, 2028, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"* input_ids: This represents the input text converted into corresponding token IDs. In this example, each input text is converted into a sequence of token IDs. For instance, [101, 7592, 1045, 1005, 1049, 1037, 2309, 6251, 102] is the token IDs for the first input text, where 101 is the ID for the [CLS] token, 102 is the ID for the [SEP] token, and the numbers in between are the IDs for individual words or subwords.\n\n* token_type_ids: This indicates which sentence each token belongs to. In BERT, each input text is split into two sentences (possibly just one sentence). In this example, the length of each list matches the length of the corresponding input_ids, indicating which sentence each token belongs to. For this task, all sentences belong to the same segment, so all values are 0.\n\n* attention_mask: This is a mask indicating which tokens are real and which are padding tokens. 1 indicates a real token, and 0 indicates a padding token. In this example, all tokens are real, so all values are 1.","metadata":{}},{"cell_type":"code","source":"#for a sentence\nencoded_input = tokenizer(\"How old are you?\", \"I'm 6 years old\")\nprint(encoded_input)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:00.153327Z","iopub.execute_input":"2024-05-06T08:26:00.153626Z","iopub.status.idle":"2024-05-06T08:26:00.161663Z","shell.execute_reply.started":"2024-05-06T08:26:00.153593Z","shell.execute_reply":"2024-05-06T08:26:00.160822Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'input_ids': [101, 2129, 2214, 2024, 2017, 1029, 102, 1045, 1005, 1049, 1020, 2086, 2214, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If you have trained your own tokenizers, you can add a method to handle pairs of sentences as follows:","metadata":{}},{"cell_type":"code","source":"# from tokenizers.processors import TemplateProcessing\n\n# tokenizer.post_processor = TemplateProcessing(\n#     single=\"[CLS] $A [SEP]\",\n#     pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n#     special_tokens=[\n#         (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n#         (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n#     ],\n# )\n\n# tokenizer.enable_truncation(max_length=512)\n# tokenizer.save(\"data/tokenizer-wiki.json\")","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:00.162610Z","iopub.execute_input":"2024-05-06T08:26:00.162847Z","iopub.status.idle":"2024-05-06T08:26:00.172296Z","shell.execute_reply.started":"2024-05-06T08:26:00.162827Z","shell.execute_reply":"2024-05-06T08:26:00.171452Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"For different data and their corresponding data formats, in order to preprocess our data, define the following dict to separately use the tokenizer to handle cases where the input is a single sentence or a sentence pair.","metadata":{}},{"cell_type":"code","source":"task_to_keys = {\n    \"cola\": (\"sentence\", None),\n    \"mnli\": (\"premise\", \"hypothesis\"),\n    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n    \"mrpc\": (\"sentence1\", \"sentence2\"),\n    \"qnli\": (\"question\", \"sentence\"),\n    \"qqp\": (\"question1\", \"question2\"),\n    \"rte\": (\"sentence1\", \"sentence2\"),\n    \"sst2\": (\"sentence\", None),\n    \"stsb\": (\"sentence1\", \"sentence2\"),\n    \"wnli\": (\"sentence1\", \"sentence2\"),\n}","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:00.175069Z","iopub.execute_input":"2024-05-06T08:26:00.175330Z","iopub.status.idle":"2024-05-06T08:26:00.182591Z","shell.execute_reply.started":"2024-05-06T08:26:00.175309Z","shell.execute_reply":"2024-05-06T08:26:00.181775Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    if sentence2_key is None:\n        return tokenizer(examples[sentence1_key], truncation=True)\n    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:00.183650Z","iopub.execute_input":"2024-05-06T08:26:00.183896Z","iopub.status.idle":"2024-05-06T08:26:00.193295Z","shell.execute_reply.started":"2024-05-06T08:26:00.183876Z","shell.execute_reply":"2024-05-06T08:26:00.192468Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We have already demonstrated the tokenizer processing a small batch. The dataset class can directly retrieve the corresponding index sentences 1 and 2, so **the above preprocessing function can handle both single samples and multiple samples.** If the input is multiple samples, the output is a list:","metadata":{}},{"cell_type":"code","source":"sentence1_key, sentence2_key = task_to_keys[task]\nprint(dataset['train'][:5])\npreprocess_function(dataset['train'][:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:00.194253Z","iopub.execute_input":"2024-05-06T08:26:00.194522Z","iopub.status.idle":"2024-05-06T08:26:00.210342Z","shell.execute_reply.started":"2024-05-06T08:26:00.194500Z","shell.execute_reply":"2024-05-06T08:26:00.209468Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'sentence': ['hide new secretions from the parental units ', 'contains no wit , only labored gags ', 'that loves its characters and communicates something rather beautiful about human nature ', 'remains utterly satisfied to remain the same throughout ', 'on the worst revenge-of-the-nerds clichÃ©s the filmmakers could dredge up '], 'label': [0, 0, 1, 0, 0], 'idx': [0, 1, 2, 3, 4]}\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102], [101, 3397, 2053, 15966, 1010, 2069, 4450, 2098, 18201, 2015, 102], [101, 2008, 7459, 2049, 3494, 1998, 10639, 2015, 2242, 2738, 3376, 2055, 2529, 3267, 102], [101, 3464, 12580, 8510, 2000, 3961, 1996, 2168, 2802, 102], [101, 2006, 1996, 5409, 7195, 1011, 1997, 1011, 1996, 1011, 11265, 17811, 18856, 17322, 2015, 1996, 16587, 2071, 2852, 24225, 2039, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"},"metadata":{}}]},{"cell_type":"markdown","source":"Next, use the **map function** to preprocess all samples in the **three sample sets in the datasets**, and apply the preprocessing function prepare_train_features to all samples.","metadata":{}},{"cell_type":"code","source":"encoded_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:00.211554Z","iopub.execute_input":"2024-05-06T08:26:00.211964Z","iopub.status.idle":"2024-05-06T08:26:03.191733Z","shell.execute_reply.started":"2024-05-06T08:26:00.211933Z","shell.execute_reply":"2024-05-06T08:26:03.190752Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36c2533aee746c3860ba1e04fa3226c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cae5edd3c38c443688c4a66b95a59406"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c099cb5ea3934cc48eac1fbf252885c8"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Finetuning Pre-trained Models","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nmodel_checkpoint = \"distilbert-base-uncased\"\nnum_labels = 3 if task.startswith(\"mnli\") else 1 if task==\"stsb\" else 2\nmodel = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:03.192890Z","iopub.execute_input":"2024-05-06T08:26:03.193821Z","iopub.status.idle":"2024-05-06T08:26:15.847938Z","shell.execute_reply.started":"2024-05-06T08:26:03.193788Z","shell.execute_reply":"2024-05-06T08:26:15.847116Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2024-05-06 08:26:06.079175: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-06 08:26:06.079288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-06 08:26:06.204288: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"010d280e62f14421af66f26be323ee73"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In order to obtain a Trainer training tool, we also need TrainingArguments for the configuration/settings of training. This training setup contains all the properties that define the training process.","metadata":{}},{"cell_type":"code","source":"batch_size = 16\nmetric_name = \"pearson\" if task == \"stsb\" else \"matthews_correlation\" if task == \"cola\" else \"accuracy\"\n\nargs = TrainingArguments(\n    \"test-glue\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=metric_name, \n)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:15.849265Z","iopub.execute_input":"2024-05-06T08:26:15.849968Z","iopub.status.idle":"2024-05-06T08:26:15.923945Z","shell.execute_reply.started":"2024-05-06T08:26:15.849930Z","shell.execute_reply":"2024-05-06T08:26:15.923160Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Another important thing, we need to choose a suitable evaluation metric to guide the model fine-tuning. We use the ðŸ¤— Datasets library to load the evaluation metric calculation library load_metric. metic is an instance of datasets.Metric:","metadata":{}},{"cell_type":"code","source":"fake_preds = np.random.randint(0, 2, size=(64,))\nfake_labels = np.random.randint(0, 2, size=(64,))\nmetric.compute(predictions=fake_preds, references=fake_labels)\n#{'matthews_correlation': 0.1513518081969605}","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:15.924978Z","iopub.execute_input":"2024-05-06T08:26:15.925242Z","iopub.status.idle":"2024-05-06T08:26:15.939587Z","shell.execute_reply.started":"2024-05-06T08:26:15.925219Z","shell.execute_reply":"2024-05-06T08:26:15.938599Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'accuracy': 0.46875}"},"metadata":{}}]},{"cell_type":"markdown","source":"Define the evaluation method for each task in Trainer as compute_metrics.","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    if task != \"stsb\":\n        predictions = np.argmax(predictions, axis=1)\n    else:\n        predictions = predictions[:, 0]\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:15.940819Z","iopub.execute_input":"2024-05-06T08:26:15.941155Z","iopub.status.idle":"2024-05-06T08:26:15.947010Z","shell.execute_reply.started":"2024-05-06T08:26:15.941121Z","shell.execute_reply":"2024-05-06T08:26:15.945983Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\"\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=encoded_dataset[\"train\"],\n    eval_dataset=encoded_dataset[validation_key],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:15.948118Z","iopub.execute_input":"2024-05-06T08:26:15.948451Z","iopub.status.idle":"2024-05-06T08:26:17.047635Z","shell.execute_reply.started":"2024-05-06T08:26:15.948422Z","shell.execute_reply":"2024-05-06T08:26:17.046785Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:26:17.048723Z","iopub.execute_input":"2024-05-06T08:26:17.048997Z","iopub.status.idle":"2024-05-06T08:43:23.197881Z","shell.execute_reply.started":"2024-05-06T08:26:17.048974Z","shell.execute_reply":"2024-05-06T08:43:23.196853Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240506_082652-twkl6gbj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/doforbetter/huggingface/runs/twkl6gbj' target=\"_blank\">devout-frog-2</a></strong> to <a href='https://wandb.ai/doforbetter/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/doforbetter/huggingface' target=\"_blank\">https://wandb.ai/doforbetter/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/doforbetter/huggingface/runs/twkl6gbj' target=\"_blank\">https://wandb.ai/doforbetter/huggingface/runs/twkl6gbj</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='21050' max='21050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [21050/21050 16:12, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.180700</td>\n      <td>0.294788</td>\n      <td>0.905963</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.136500</td>\n      <td>0.384246</td>\n      <td>0.901376</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.092200</td>\n      <td>0.395704</td>\n      <td>0.902523</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.070700</td>\n      <td>0.445318</td>\n      <td>0.909404</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.043800</td>\n      <td>0.490704</td>\n      <td>0.907110</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=21050, training_loss=0.11176590635204542, metrics={'train_runtime': 1025.8321, 'train_samples_per_second': 328.265, 'train_steps_per_second': 20.52, 'total_flos': 3067639398189732.0, 'train_loss': 0.11176590635204542, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:48:51.494631Z","iopub.execute_input":"2024-05-06T08:48:51.495489Z","iopub.status.idle":"2024-05-06T08:48:52.425663Z","shell.execute_reply.started":"2024-05-06T08:48:51.495447Z","shell.execute_reply":"2024-05-06T08:48:52.424659Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [55/55 00:00]\n    </div>\n    "},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.4453180730342865,\n 'eval_accuracy': 0.9094036697247706,\n 'eval_runtime': 0.9142,\n 'eval_samples_per_second': 953.8,\n 'eval_steps_per_second': 60.159,\n 'epoch': 5.0}"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"/kaggle/working/param\")","metadata":{"execution":{"iopub.status.busy":"2024-05-06T08:53:43.846331Z","iopub.execute_input":"2024-05-06T08:53:43.847170Z","iopub.status.idle":"2024-05-06T08:53:44.312709Z","shell.execute_reply.started":"2024-05-06T08:53:43.847140Z","shell.execute_reply":"2024-05-06T08:53:44.311570Z"},"trusted":true},"execution_count":23,"outputs":[]}]}